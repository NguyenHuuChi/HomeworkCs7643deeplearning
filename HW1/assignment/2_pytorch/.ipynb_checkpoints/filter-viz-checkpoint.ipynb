{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the trained filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some startup! \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# This is needed to save images \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model saved by train.py\n",
    "# This will be an instance of models.softmax.Softmax.\n",
    "# NOTE: You may need to change this file name.\n",
    "softmax_model = torch.load('softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=3072, out_features=10, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[ 7.0296e-03, -3.9915e-03, -2.8194e-03,  ...,  1.7208e-04,\n",
      "          5.7219e-03, -3.9470e-03],\n",
      "        [ 6.4316e-03, -8.1388e-03, -5.1848e-03,  ..., -8.6552e-03,\n",
      "          4.3228e-03,  1.0055e-02],\n",
      "        [-1.0587e-04,  5.2646e-03, -3.2682e-03,  ...,  4.5158e-03,\n",
      "          6.5085e-03, -8.5476e-03],\n",
      "        ...,\n",
      "        [-3.4848e-03, -7.0659e-03,  3.8347e-03,  ...,  2.2186e-03,\n",
      "         -5.5000e-03, -5.2893e-03],\n",
      "        [-4.5493e-04,  8.3179e-03,  1.6668e-03,  ...,  3.7662e-03,\n",
      "          8.9277e-05,  1.2778e-02],\n",
      "        [-5.0492e-03, -2.1763e-03, -5.2148e-03,  ..., -7.4048e-03,\n",
      "         -7.0238e-03,  3.8442e-03]], requires_grad=True)\n",
      "(10, 3072)\n"
     ]
    }
   ],
   "source": [
    "#print(list(softmax_model.parameters()))\n",
    "print(softmax_model.linear.cpu())\n",
    "print(softmax_model.linear.cpu().weight)\n",
    "w = softmax_model.linear.cpu().weight.data.numpy()\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved\n"
     ]
    }
   ],
   "source": [
    "# collect all the weights\n",
    "w = None\n",
    "#############################################################################\n",
    "# TODO: Extract the weight matrix (without bias) from softmax_model, convert\n",
    "# it to a numpy array with shape (10, 32, 32, 3), and assign this array to w.\n",
    "# The first dimension should be for channels, then height, width, and color.\n",
    "# This step depends on how you implemented models.softmax.Softmax.\n",
    "#############################################################################\n",
    "w = softmax_model.linear.cpu().weight.data.numpy()\n",
    "w = w.reshape(10,32,32,3)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "# obtain min,max to normalize\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "# classes\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# init figure \n",
    "fig = plt.figure(figsize=(6,6))\n",
    "for i in range(10):\n",
    "    wimg = 255.0*(w[i].squeeze() - w_min) / (w_max - w_min)\n",
    "    # subplot is (2,5) as ten filters are to be visualized\n",
    "    fig.add_subplot(2,5,i+1).imshow(wimg.astype('uint8'))\n",
    "# save fig! \n",
    "fig.savefig('softmax_filt.png')\n",
    "print('figure saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved as a grid!\n"
     ]
    }
   ],
   "source": [
    "# vis_utils.py has helper code to view multiple filters in single image. Use this to visuzlize \n",
    "# neural network. \n",
    "# import vis_utils\n",
    "from vis_utils import visualize_grid\n",
    "# saving the weights is now as simple as:\n",
    "plt.imsave('softmax_gridfilt.png',visualize_grid(w, padding=3).astype('uint8'))\n",
    "# padding is the space between images. Make sure that w is of shape: (N,H,W,C)\n",
    "print('figure saved as a grid!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two layer nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_layer_nn_model = torch.load('twolayernn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=3072, out_features=48, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0070, -0.0032, -0.0012,  ...,  0.0004,  0.0062, -0.0030],\n",
      "        [ 0.0070, -0.0094, -0.0069,  ..., -0.0108,  0.0017,  0.0076],\n",
      "        [ 0.0072,  0.0102, -0.0028,  ...,  0.0071,  0.0100, -0.0056],\n",
      "        ...,\n",
      "        [-0.0038,  0.0004, -0.0001,  ...,  0.0062,  0.0031, -0.0030],\n",
      "        [ 0.0048,  0.0040, -0.0112,  ...,  0.0105, -0.0034, -0.0032],\n",
      "        [-0.0001,  0.0093, -0.0037,  ..., -0.0025,  0.0054,  0.0018]],\n",
      "       requires_grad=True)\n",
      "(48, 3072)\n"
     ]
    }
   ],
   "source": [
    "print(two_layer_nn_model.layer1.cpu())\n",
    "print(two_layer_nn_model.layer1.cpu().weight)\n",
    "w = two_layer_nn_model.layer1.cpu().weight.data.numpy()\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = w.reshape(48,32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "figure saved as a grid!\n"
     ]
    }
   ],
   "source": [
    "# vis_utils.py has helper code to view multiple filters in single image. Use this to visuzlize \n",
    "# neural network. \n",
    "# import vis_utils\n",
    "from vis_utils import visualize_grid\n",
    "# saving the weights is now as simple as:\n",
    "plt.imsave('twolayernn_gridfilt.png',visualize_grid(w, padding=3).astype('uint8'))\n",
    "# padding is the space between images. Make sure that w is of shape: (N,H,W,C)\n",
    "print('figure saved as a grid!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
